#+TITLE: Managed Runtime Systems
#+SUBTITLE: Just In Time Compilation Part 1
#+AUTHOR: Foivos Zakkak
#+EMAIL: foivos@zakkak.net
#+DATE: 2021-02-16
#+INCLUDE: ./99-ox-reveal-setup.org
#+INCLUDE: ./99-license.org

** Acknowledgments
The following slides are based on [[http://www.wolczko.com/][Mario Wolczko's]] slides about [[https://www.dropbox.com/s/hqc2axihgvxtadf/10\%20Dynamic\%20compilation.pdf][/Dynamic Compilation/]]

* Introduction

** Interpretation is Slow
Step a single (or a few) bytecode(s) a time

Not suitable execution patterns for HW-prefetchers

Not enough data at hand to perform optimizations

** Dynamic Compilation to the Rescue
Produce machine code

Better execution patterns for HW-prefetchers

More data at hand to perform optimizations

Generation of HW-specific code

Generation of case-specific code

* Dynamic Compiler Design Decisions

** How Much to Compile?
Basic Block

Method

Multiple Methods (via inlining)

Multiple Consecutive Methods (via tracing)

** When to Compile?
*** Ahead of Time (AoT)
At class loading

At installation (see Android's dex2oat)

*** Pedantic Just in Time (JIT)
Compile at first invocation
(stall till compilation completes)

Re-use on later invocations

*** Practical JIT
Start compiling after $n$ invocations

Interpret while compiling to avoid stalls

** How Much to Optimize?
*** Minimal
Replace *bytecodes* with function calls,
like macro expansion

*** Simple
Use HW-registers

Perform *peephole* optimizations
(substituting instruction sequences with more efficient ones)

*** Advanced
Run various analyses on code

Generate multiple instances of same method for different cases

...

* When to JIT

** So! When should I JIT compile?
#+REVEAL_HTML: <div class="column" style="float:left; width:50%; text-align:left; font-size:90%">
Key factors:
- Speed of *interpretation*
- Speed of *compilation*
- Speed of *compiled code*
#+REVEAL_HTML: </div>
#+REVEAL_HTML: <div class="column" style="float:right; width:50%">
#+begin_src python :exports results :results file :var f="./figures/when-to-jit-1.svg"
import sys
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

sns.set(font_scale=1.25)
sns.set_style("white")
plt.figure(figsize=(4.5, 4), dpi=100)

data = pd.DataFrame(np.array([[0, 0], [1, 2.5], [2, 3], [3, 3.5], [4, 4], [5, 4.5]]))
data.columns = ['A', 'B']
ax = sns.lineplot(data=data, palette="pastel", legend=False, linewidth=4, markers=["o", "v"], markersize=15);
ax.set_ylabel("Time");
ax.set_xlabel("Number of Executions");
ax.set(ylim=(0,5.5), xlim=(0,5.5))
sns.despine()
plt.tight_layout();
plt.savefig(f);
return f;
#+end_src

#+RESULTS:
[[file:./figures/when-to-jit-1.svg]]
#+REVEAL_HTML: </div>

** Measuring Speed
- Measure the *whole run* in *clock cycles*
- *Subtract* GC time, native code, and anything unrelated
- Divide by number of bytecodes to obtain *cycles per bytecode*

** Measuring Speed
- Interpretation time *$t_i$*
- Compilation time *$t_c$*
- Execution time of compiled code *$t_e$*
- Compiler over Interpreter ratio *$\tau = {t_c \over t_i}$* (mnemonic: translate)
- Interpreter over Compiled code ratio *$\rho = {t_i \over t_e}$* (mnemonic: run)

** The break-even point

*$\beta = {t_c \over t_i - t_e} = {{\rho \tau} \over \rho - 1}$*

Example: $t_e = 1$, $t_i = 2$, $t_c = 10$, $\tau = 5$, $\rho = 2$, $\beta = 10$

#+REVEAL: split

$\beta = {{\rho \tau} \over \rho - 1}$

#+begin_src python :exports results :results file :var f="./figures/when-to-jit-2.svg"
import sys
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

sns.set(font_scale=1.25)
sns.set_style("white")
plt.figure(figsize=(9.6, 5), dpi=100)

t = [1, 2, 5, 10, 20, 50, 100]

x = np.linspace(1.01,20,1000)
y = x/(x-1)

for i in t:
    ax = sns.lineplot(x, y*i, palette="pastel", linewidth=3, label="τ="+str(i));
ax.set_ylabel("β");
ax.set_xlabel("ρ");
ax.set_yscale('log')
ax.set(ylim=(0,10000), xlim=(0,20))
ax.legend(ncol=4)
sns.despine()

# plt.plot(x, y*i, label="τ="+str(i))
plt.tight_layout();
plt.savefig(f);
return f;
#+end_src

#+RESULTS:
[[file:./figures/when-to-jit-2.svg]]

#+REVEAL: split
$\mathrm{Speedup} = {{n t_i} \over t_c + n t_e} = {{n \rho} \over n + \rho \tau}$ for $\rho = 5$, $\tau = 100$

#+begin_src python :exports results :results file :var f="./figures/when-to-jit-3.svg"
import sys
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

sns.set(font_scale=1.25)
sns.set_style("white")
plt.figure(figsize=(9.6, 5), dpi=100)

x = np.linspace(0,1000000,10000)
y = x*5/(x+5*100)

ax = sns.lineplot(x, y, palette="pastel", linewidth=3, legend=False);
sns.lineplot(x, 1, palette="pastel", linewidth=1, label="y=1");
sns.lineplot(x, 5, palette="pastel", linewidth=1, label="y=ρ");
ax.plot([125,5], [125,0], label="x=125")
ax.legend()
for i in range(1,4):
    ax.lines[i].set_linestyle("--")
ax.set_ylabel("β");
ax.set_xlabel("ρ");
ax.set_yscale('log')
ax.set_xscale('log')
ax.set(ylim=(0.008,10), xlim=(1,1000000))
sns.despine()

# plt.plot(x, y*i, label="τ="+str(i))
plt.tight_layout();
plt.savefig(f);
return f;
#+end_src

#+RESULTS:
[[file:./figures/when-to-jit-3.svg]]

* How to JIT

** Interaction of JITed and non-JITed Code
JITed code can invoke non-JITed code

JITed code can fall-back to non-JITed counterpart

** JITed Code Management
- Maintain a *code cache* holding the JITed code
- VMs manage it to ensure new code can be added when needed
- Compilers rely on a big buffer to produce the code
- The JITed code is then copied to the code cache
- Calls to that code are redirected (e.g. through method tables)

** When to Remove Code
When the corresponding code *becomes unreachable*
(e.g. class unloading)

When the code cache doesn't have enough *space for new code*

** What if Still Active?
- Keep an *activation-counter*
- *Scan* the stacks for activation records
#+ATTR_REVEAL: :frag t
Sounds familiar?

** Stack Scanning
- *Walk the stack* looking for return addresses
- The *calling convention* must allow it
  - Standard placement of return addresses in the stack
  - Access to saved registers (e.g. SP, FP) of suspended threads
- Depends on underlying, architecture, OS, and calling convention
- The OS can make this *impossible*
  (e.g., by saving register state in kernel space).

** What if Still Active?
- Let it be
- Drop it and patch any activation records pointing to it
  - Do the housekeeping (fix state, fix return address, etc.)
  - Make it resume in the interpreter
  - Called *dynamic deoptimization*
  - It's slow!!!

** What About Fragmentation in the Code Cache
Self VM uses *compaction*
  - Similar to GC
  - Stop the world
  - Compact code cache
  - Update links (method tables) and return addresses (activation records)

HotSpot drops code till enough space becomes available

** Using the Heap
Make compiled code an object in the heap

Pros:
- *Share* memory management mechanisms

Cons:
- Compiled code usually *lives long*
- A bug may give *write access to generated code*

* Impact of JITed Code on Garbage Collection

*More* roots

Pointers might be:
  - in *HW-registers*
  - *stack frames* of JITed code
  - or even *hardcoded* in the JITed code (as literals)

A HW-register might even contain a pointer in the middle of (de)construction, e.g. pointer arithmetic

** Keeping Track of Roots in Registers
- All activations (except the top) are at a *call site*
- For each call site keep a *register map*
- The register map indicates which registers are live

** Keeping Track of Roots in Registers: Example
- Self compilers inject a register map word after each call
  each bit represents a register, with the bit set if the register is live and has an oop
- The return sequence skips over the map
- A simple stack scan locates all the register maps

** Keeping Track of Roots in Registers of Top Frame
- No root call site with register map
- Can be suspended at any instruction

-----

- Only allow suspension at GC *safe points*, with register maps
- Maintain register maps at fixed locations and use *abstract interpretation* to derive the map at current point
- *Replay* the compiler to produce the register map(s)

** GC Safe Points
Safe points are placed at JITed *code entry and back-branches*

At safe points *ask the VM* whether the thread should suspend

To stop-the-world all threads need to *reach a safe point*

Waiting others to reach a safe point, threads can *scan themselves*

** Keeping Track of Roots on the Stack
Keep *stack maps* for each call site

Keep the stack maps in the code cache

Add a pointer to them after the call

** Keeping Track of Roots in the Code
If the compiler hardcodes pointers in the JITed code:

- It might be in complex form
  e.g., *piecemeal assembly*
- The compiler emits a table identifying the locations of these refs
- The VM needs to be able to use them as roots
- The VM needs to be able to alter them if needed

* Interesting Facts About JIT
Term originates from just-in-time manufacturing
(aka kanban method)

Appeared around the time of Java’s uptake

Terrible misnomer (should be *just too late*)

Universally misapplied
(e.g., to dynamic compilation *after* first execution)

"JIT" is *not a noun*
